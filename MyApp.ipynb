{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# import zipfile\r\n",
        "# from google.colab import drive \r\n",
        "# drive.mount('/content/gdrive') "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "!pip install flask-ngrok\r\n",
        "# Additional Dependencies\r\n",
        "!pip install barbar torchsummary\r\n",
        "from myImports import *\r\n",
        "from ConvAutoencoder_v2 import ConvAutoencoder_v2\r\n",
        "from utils import Utils\r\n",
        "from UploadFiles import UploadFiles\r\n",
        "util = Utils()\r\n",
        "# Find if any accelerator is presented, if yes switch device to use CUDA or else use CPU\r\n",
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "# print(device)\r\n",
        "# creating an instance of a flask web application\r\n",
        "app = Flask(__name__, static_folder = 'static', template_folder='templates')\r\n",
        "run_with_ngrok(app)\r\n",
        "app.secret_key = \"secret key\"\r\n",
        "# Get current path\r\n",
        "path = os.getcwd()\r\n",
        "# file Upload\r\n",
        "UPLOAD_FOLDER = os.path.join(path, 'uploads')\r\n",
        "# Make directory if \"uploads\" folder not exists\r\n",
        "if not os.path.isdir(UPLOAD_FOLDER):\r\n",
        "    os.mkdir(UPLOAD_FOLDER)\r\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\r\n",
        "QUERYIMAGEPATH = app.config['UPLOAD_FOLDER'] + '\\\\QueryImage\\\\'\r\n",
        "\r\n",
        "CSVFILEPATH = app.config['UPLOAD_FOLDER'] + '\\\\CsvFile\\\\'\r\n",
        "\r\n",
        "# Allowed extension you can set your own\r\n",
        "ALLOWED_EXTENSIONS = set(['csv', 'png', 'jpg', 'jpeg', 'zip'])\r\n",
        "\r\n",
        "transformations = util.getTransformations()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in d:\\programs\\python\\lib\\site-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in d:\\programs\\python\\lib\\site-packages (from flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: requests in d:\\programs\\python\\lib\\site-packages (from flask-ngrok) (2.25.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in d:\\programs\\python\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: Werkzeug>=2.0 in d:\\programs\\python\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: click>=7.1.2 in d:\\programs\\python\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (8.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in d:\\programs\\python\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n",
            "Requirement already satisfied: colorama in d:\\programs\\python\\lib\\site-packages (from click>=7.1.2->Flask>=0.8->flask-ngrok) (0.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\programs\\python\\lib\\site-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in d:\\programs\\python\\lib\\site-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\programs\\python\\lib\\site-packages (from requests->flask-ngrok) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\python\\lib\\site-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programs\\python\\lib\\site-packages (from requests->flask-ngrok) (1.26.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
            "You should consider upgrading via the 'd:\\programs\\python\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: barbar in d:\\programs\\python\\lib\\site-packages (0.2.1)\n",
            "Requirement already satisfied: torchsummary in d:\\programs\\python\\lib\\site-packages (1.5.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution - (d:\\programs\\python\\lib\\site-packages)\n",
            "WARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
            "You should consider upgrading via the 'd:\\programs\\python\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "#Define the route \"how to access a specific page\"\r\n",
        "@app.route('/', methods=['GET'])\r\n",
        "def dashboard_page():\r\n",
        "    return render_template('dashboard.html')\r\n",
        "\r\n",
        "\r\n",
        "@app.route('/trainModelPage', methods=['GET','POST'])\r\n",
        "def train_model_page():\r\n",
        "    \r\n",
        "\r\n",
        "    if request.method == \"POST\":\r\n",
        "        # if 'action' in request.form:\r\n",
        "        #     print('request.files.getlist',request.files.getlist)\r\n",
        "        # if action == 'upload':\r\n",
        "        action = request.form['action']\r\n",
        "        print(action)\r\n",
        "        if action == 'upload':\r\n",
        "            if 'file' not in request.files:\r\n",
        "                flash('No file parts')\r\n",
        "                #print(\"sdsd\")\r\n",
        "                return redirect(request.url)\r\n",
        "            filesize =   request.cookies.get('filesize')  \r\n",
        "            file =  request.files['file']\r\n",
        "            print(f\"Filesize: {filesize}\")\r\n",
        "            print(file)\r\n",
        "            \r\n",
        "            #print(\"ssss\", app.config['UPLOAD_FOLDER'])\r\n",
        "            train_set = UploadFiles(app.config['UPLOAD_FOLDER'], request.files)\r\n",
        "            #print(\"aAS\")\r\n",
        "            train_set_path = train_set.upload()\r\n",
        "            #print(train_set_path)\r\n",
        "            os.path.exists(os.path.abspath(train_set_path))\r\n",
        "            #print('ss', train_set_path)\r\n",
        "\r\n",
        "            session['train_set_path'] = train_set_path\r\n",
        "\r\n",
        "            images_to_display = []\r\n",
        "            counter = 0\r\n",
        "            for dirname, _, filenames in os.walk(train_set_path):\r\n",
        "                for filename in filenames:\r\n",
        "                    if counter == 8:\r\n",
        "                        break\r\n",
        "                    temp_list = []\r\n",
        "                    temp_list.append(dirname)\r\n",
        "                    temp_list.append(filename)\r\n",
        "                    # imagePath = os.path.join(dirname, filename)\r\n",
        "                    images_to_display.append(temp_list)\r\n",
        "                    counter = counter + 1\r\n",
        "\r\n",
        "            nbrFiles = 0\r\n",
        "            for dirname, _, filenames in os.walk(train_set_path):\r\n",
        "                for filename in filenames:\r\n",
        "                    nbrFiles = nbrFiles + 1\r\n",
        "            print('nbr ',nbrFiles)\r\n",
        "            #print(images_to_display)\r\n",
        "\r\n",
        "            print(\"File uploaded\")\r\n",
        "            \r\n",
        "            # json_images_to_display = json.dumps(images_to_display)\r\n",
        "            # print(json_images_to_display)\r\n",
        "            #res = make_response(jsonify(images_to_display=json_images_to_display), 200)\r\n",
        "            return jsonify({'data': render_template('list.html', images_to_display=images_to_display, nbrFiles=nbrFiles), 'nbrFiles': nbrFiles})\r\n",
        "\r\n",
        "        elif action == 'train':\r\n",
        "            optimizer = request.form['optimizer']\r\n",
        "            learnin_rate = request.form['lr']\r\n",
        "            epochs = request.form['epochs']\r\n",
        "            batch_size = request.form['batchsize']\r\n",
        "            modelName = request.form['modelName']\r\n",
        "            print(modelName)\r\n",
        "\r\n",
        "            model_name_info_ = modelName +'_'+  optimizer +'_'+ learnin_rate +'_'+ epochs  +'_'+ batch_size\r\n",
        "            \r\n",
        "            \r\n",
        "            # #TODO add function called train with parameters\r\n",
        "            #Check if first if there any information in the session\r\n",
        "            if \"train_set_path\" in session:\r\n",
        "                train_set_path = session['train_set_path']\r\n",
        "                #print('sldflsdjflk')\r\n",
        "            else:\r\n",
        "                #print('aaaaa')\r\n",
        "                render_template('train_model.html')\r\n",
        "\r\n",
        "\r\n",
        "                \r\n",
        "            #TODO add function to preparing trainset intermediate DataFrame\r\n",
        "            # preparing intermediate DataFrame\r\n",
        "            datasetPath = Path(train_set_path)\r\n",
        "            df = pd.DataFrame()\r\n",
        "            myfilename = [] \r\n",
        "            for dirname, _, filenames in os.walk(datasetPath):\r\n",
        "                for filename in filenames:\r\n",
        "                    #print(os.path.join(dirname, filename))\r\n",
        "                    myfilename.append(os.path.join(dirname, filename))\r\n",
        "            df['image'] = myfilename\r\n",
        "            df.head()\r\n",
        "            #print(df)\r\n",
        "\r\n",
        "            EPOCHS = int(epochs)\r\n",
        "            NUM_BATCHES = int(batch_size)\r\n",
        "            RETRAIN = False\r\n",
        "\r\n",
        "            # EPOCHS,NUM_BATCHES,df, \r\n",
        "            train_set, validate_set = util.prepare_data(DF=df)\r\n",
        "\r\n",
        "            dataloaders = {'train': DataLoader(train_set, batch_size=NUM_BATCHES, shuffle=True, num_workers=1) ,\r\n",
        "                            'val':DataLoader(validate_set, batch_size=NUM_BATCHES, num_workers=1)\r\n",
        "                            }\r\n",
        "\r\n",
        "            #To show images\r\n",
        "            # images = next(iter(DataLoader(train_set, batch_size=NUM_BATCHES, shuffle=True, num_workers=1)))\r\n",
        "            # helper.imshow(images[31], normalize=False)\r\n",
        "\r\n",
        "            dataset_sizes = {'train': len(train_set),'val':len(validate_set)}\r\n",
        "\r\n",
        "            model = ConvAutoencoder_v2().to(device)\r\n",
        "\r\n",
        "            criterion = nn.MSELoss()\r\n",
        "            # Observe that all parameters are being optimized\r\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=float(learnin_rate)) if (optimizer==\"Adam\") else torch.optim.SGD(model.parameters(), lr=float(learnin_rate)) \r\n",
        "            # Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "            exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)#this was commented\r\n",
        "\r\n",
        "            #Training Fucntions\r\n",
        "            model, optimizer, loss = util.train_model(\r\n",
        "                            model=model,\r\n",
        "                            dataloaders = dataloaders,\r\n",
        "                            dataset_sizes = dataset_sizes,\r\n",
        "                            criterion=criterion, \r\n",
        "                            optimizer=optimizer, \r\n",
        "                            scheduler=exp_lr_scheduler,\r\n",
        "                            num_epochs=EPOCHS)\r\n",
        "\r\n",
        "            \r\n",
        "            #Save the trained model \r\n",
        "            torch.save({ 'epoch': EPOCHS, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': loss, }, app.config['UPLOAD_FOLDER']+'/Models/'+model_name_info_+'.pt')\r\n",
        "            res = make_response(jsonify({\"message\": \"Model Trained\"}), 200)\r\n",
        "            return res\r\n",
        "\r\n",
        "        else: print('welcome to bouzidia')\r\n",
        "\r\n",
        "        #return res\r\n",
        "    return render_template('train_model.html') #,images_to_display=images_to_display\r\n",
        "    #return redirect(url_for('train_and_save'))\r\n",
        "\r\n",
        "\r\n",
        "@app.route('/searchPage', methods=['GET'])\r\n",
        "def search_page():\r\n",
        "    models_folder_path = app.config['UPLOAD_FOLDER']+'\\\\Models\\\\'\r\n",
        "    list_of_models = []\r\n",
        "    for path,dirs,files in os.walk(models_folder_path):\r\n",
        "        for filename in files:\r\n",
        "            temp_list = []\r\n",
        "            temp_list.append(filename)\r\n",
        "            temp_list.append(path)\r\n",
        "            list_of_models.append(temp_list)\r\n",
        "            print(os.path.join(path,filename))\r\n",
        "\r\n",
        "    return render_template('retreive_images.html', list_of_models = list_of_models)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "from json import JSONEncoder\r\n",
        "\r\n",
        "class NumpyArrayEncoder(JSONEncoder):\r\n",
        "    def default(self, obj):\r\n",
        "        if isinstance(obj, np.ndarray):\r\n",
        "            return obj.tolist()\r\n",
        "        return JSONEncoder.default(self, obj)\r\n",
        "\r\n",
        "@app.route('/extractTestSetFeaturesFolder', methods=['POST'])\r\n",
        "def extract_test_set_features_folder():\r\n",
        "    # print('extraxtion form is here', request.form , request.files)\r\n",
        "\r\n",
        "    if 'dataSet' not in request.files:\r\n",
        "        # flash('No file parts')\r\n",
        "        #print(\"sdsd\")\r\n",
        "        return redirect(request.url)\r\n",
        "    #print(\"ssss\", app.config['UPLOAD_FOLDER'])\r\n",
        "    test_set = UploadFiles(app.config['UPLOAD_FOLDER'], request.files)\r\n",
        "    #print(\"aAS\")\r\n",
        "    test_set_path = test_set.upload('dataSet')\r\n",
        "    #print(test_set_path)\r\n",
        "    os.path.exists(os.path.abspath(test_set_path))\r\n",
        "    #print('ss', test_set_path)\r\n",
        "\r\n",
        "    session['test_set_path'] = test_set_path\r\n",
        "\r\n",
        "\r\n",
        "    print(test_set_path)\r\n",
        "    ###############################################################Labels From folder name####################################################\r\n",
        "    datasetPath = Path(test_set_path) \r\n",
        "    df = pd.DataFrame()\r\n",
        "    myimagepath = [] \r\n",
        "    classesname = []\r\n",
        "    filesname = []\r\n",
        "    directoryname = []\r\n",
        "    for dirname, _, filenames in os.walk(datasetPath):\r\n",
        "        for filename in filenames:\r\n",
        "            directoryname.append(dirname)\r\n",
        "            imagePath = os.path.join(dirname, filename)\r\n",
        "            filesname.append(filename)\r\n",
        "            myimagepath.append(imagePath)\r\n",
        "            c = util.getImageClass(imagePath)\r\n",
        "            #print(filename, c, )\r\n",
        "            classesname.append(c)\r\n",
        "            # print(filesname)        \r\n",
        "    df['image'] ,df['classe'], df['filename'],df['directoryname']= [myimagepath,classesname,filesname,directoryname]\r\n",
        "    df.head()\r\n",
        "\r\n",
        "    selected_model = request.form['modal']\r\n",
        "    print(selected_model)\r\n",
        "\r\n",
        "    loaded_model = util.load_model_from_dir(selected_model)\r\n",
        "    session['model_path'] = selected_model\r\n",
        "\r\n",
        "    print('sesssion : ' , session['model_path'] ) \r\n",
        "\r\n",
        "    _, classes, _, index_dict ,filesNames, diractoriesNames= util.features_extraction_and_index_creation(df, transformations,loaded_model)\r\n",
        "\r\n",
        "    ###########Features##############\r\n",
        "    # write the data dictionary to disk\r\n",
        "    print(\"[INFO] saving index...\")\r\n",
        "    f = open(app.config['UPLOAD_FOLDER'] +'/'+ 'index_dict.pickle', \"wb\")\r\n",
        "    f.write(pickle.dumps(index_dict))\r\n",
        "    f.close()\r\n",
        "    ##############Sendding other paramts####################\r\n",
        "    my_params = {'diractoriesNames': diractoriesNames, 'filesNames': filesNames, 'classes': classes}\r\n",
        "\r\n",
        "\r\n",
        "    print(\"[INFO] saving diractoriesNames...\")\r\n",
        "    f = open(app.config['UPLOAD_FOLDER'] +'/'+ 'my_params.pickle', \"wb\")\r\n",
        "    f.write(pickle.dumps(my_params))\r\n",
        "    f.close()\r\n",
        "\r\n",
        "    return jsonify('success')\r\n",
        "\r\n",
        "    #return render_template('retreive_images.html')\r\n",
        "\r\n",
        "\r\n",
        "@app.route('/extractTestSetFeaturesExcel', methods=['POST'])\r\n",
        "def extract_test_set_features_excel():\r\n",
        "    print('extraxtion form is here EXceeeeeeeeeeeeeeeeeeel', request.form , request.files)\r\n",
        "\r\n",
        "    classColumn = request.form['classColumn']\r\n",
        "    imageIdColumn = request.form['imageIdColumn']\r\n",
        "    selected_model = request.form['modal']\r\n",
        "\r\n",
        "    #import dataset\r\n",
        "    if 'dataSet' not in request.files:\r\n",
        "        return redirect(request.url)\r\n",
        "    test_set = UploadFiles(app.config['UPLOAD_FOLDER'], request.files)\r\n",
        "    test_set_path = test_set.upload('dataSet')\r\n",
        "    os.path.exists(os.path.abspath(test_set_path))\r\n",
        "    # session['test_set_path'] = test_set_path\r\n",
        "\r\n",
        "    if 'csvFile' not in request.files:\r\n",
        "        return redirect(request.url)\r\n",
        "    csvFile = request.files['csvFile']\r\n",
        "    csvfileName = csvFile.filename\r\n",
        "    csv_path = CSVFILEPATH +  csvfileName\r\n",
        "    csvFile.save(csv_path)\r\n",
        "\r\n",
        "\r\n",
        "    classes_data = pd.read_csv(csv_path,sep=';') \r\n",
        "    classes_data = classes_data.set_index(imageIdColumn, drop = False)\r\n",
        "    # preparing intermediate DataFrame\r\n",
        "    datasetPath = Path(test_set_path)\r\n",
        "    df = pd.DataFrame()\r\n",
        "    myimagepath = [] \r\n",
        "    classesname = []\r\n",
        "    filesname = []\r\n",
        "    directoryname = []\r\n",
        "    for dirname, _, filenames in os.walk(datasetPath):\r\n",
        "        for filename in filenames:\r\n",
        "            directoryname.append(dirname)\r\n",
        "            imagePath = os.path.join(dirname, filename)\r\n",
        "            filesname.append(filename)\r\n",
        "            myimagepath.append(imagePath)\r\n",
        "            imageID = util.getImageID(filename)\r\n",
        "            classesname.append(classes_data.at[int(imageID),classColumn])       \r\n",
        "    df['image'] ,df['classe'], df['filename'],df['directoryname']= [myimagepath,classesname,filesname,directoryname]\r\n",
        "\r\n",
        "    loaded_model = util.load_model_from_dir(selected_model)\r\n",
        "    \r\n",
        "    session['model_path'] = selected_model\r\n",
        "\r\n",
        "    print('sesssion : ' , session['model_path'] ) \r\n",
        "    _, classes, _, index_dict ,filesNames, diractoriesNames= util.features_extraction_and_index_creation(df, transformations,loaded_model)\r\n",
        "   \r\n",
        "    # write the data dictionary to disk\r\n",
        "    print(\"[INFO] saving index...\")\r\n",
        "    f = open('index_dict.pickle', \"wb\")\r\n",
        "    f.write(pickle.dumps(index_dict))\r\n",
        "    f.close()\r\n",
        "\r\n",
        "    return jsonify('success')\r\n",
        "\r\n",
        "\r\n",
        "@app.route('/upload/<path>/<filename>')\r\n",
        "def download_file(path, filename):\r\n",
        "    return send_from_directory(path, filename, as_attachment=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Train Set, Test Set\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# #TODO add function to load train set\r\n",
        "# #Uploading Training Set\r\n",
        "# creating an instance of a flask web application\r\n",
        "\r\n",
        "train_set_path = ''\r\n",
        "\r\n",
        "# @app.route('/trainModelPage', methods=['GET','POST'])\r\n",
        "# def upload_Train_set():\r\n",
        "#     if request.method == \"POST\":\r\n",
        "#         if 'file' not in request.files:\r\n",
        "#             flash('No file parts')\r\n",
        "#             #print(\"sdsd\")\r\n",
        "#             return redirect(request.url)\r\n",
        "#         filesize =   request.cookies.get('filesize')  \r\n",
        "#         file =  request.files['file']\r\n",
        "#         print(f\"Filesize: {filesize}\")\r\n",
        "#         print(file)\r\n",
        "#         # #print(\"ssss\", app.config['UPLOAD_FOLDER'])\r\n",
        "#         # train_set = UploadFiles(app.config['UPLOAD_FOLDER'], request.files)\r\n",
        "#         # #print(\"aAS\")\r\n",
        "#         # train_set_path = train_set.upload()\r\n",
        "#         # #print(train_set_path)\r\n",
        "#         # os.path.exists(os.path.abspath(train_set_path))\r\n",
        "#         # #print('ss', train_set_path)\r\n",
        "\r\n",
        "#         # session['train_set_path'] = train_set_path\r\n",
        "\r\n",
        "#         # images_to_display = []\r\n",
        "#         # counter = 0\r\n",
        "#         # for dirname, _, filenames in os.walk(train_set_path):\r\n",
        "#         #     for filename in filenames:\r\n",
        "#         #         if counter == 8:\r\n",
        "#         #             break\r\n",
        "#         #         temp_list = []\r\n",
        "#         #         temp_list.append(dirname)\r\n",
        "#         #         temp_list.append(filename)\r\n",
        "#         #         # imagePath = os.path.join(dirname, filename)\r\n",
        "#         #         images_to_display.append(temp_list)\r\n",
        "#         #         counter = counter + 1\r\n",
        "\r\n",
        "#         # #print(images_to_display)\r\n",
        "\r\n",
        "#         print(\"File uploaded\")\r\n",
        "\r\n",
        "#         res = make_response(jsonify({\"message\": f\"{file.filename} uploaded\"}), 200)\r\n",
        "\r\n",
        "#         return res\r\n",
        "#     return render_template('train_model.html') #,images_to_display=images_to_display\r\n",
        "#     #return redirect(url_for('train_and_save'))\r\n",
        "\r\n",
        "# # #TODO add function to load test set\r\n",
        "# # #Uploading Testing Set\r\n",
        "@app.route('/uploadTestSet', methods=['POST'])\r\n",
        "def upload_Test_set():\r\n",
        "    if 'file' not in request.files:\r\n",
        "        flash('No file parts')\r\n",
        "        #print(\"sdsd\")\r\n",
        "        return redirect(request.url)\r\n",
        "    #print(\"ssss\", app.config['UPLOAD_FOLDER'])\r\n",
        "    test_set = UploadFiles(app.config['UPLOAD_FOLDER'], request.files)\r\n",
        "    #print(\"aAS\")\r\n",
        "    test_set_path = test_set.upload()\r\n",
        "    #print(test_set_path)\r\n",
        "    os.path.exists(os.path.abspath(test_set_path))\r\n",
        "    #print('ss', test_set_path)\r\n",
        "\r\n",
        "    session['test_set_path'] = test_set_path\r\n",
        "\r\n",
        "    images_to_display = []\r\n",
        "    counter = 0\r\n",
        "    for dirname, _, filenames in os.walk(test_set_path):\r\n",
        "        for filename in filenames:\r\n",
        "            if counter == 8:\r\n",
        "                break\r\n",
        "            temp_list = []\r\n",
        "            temp_list.append(dirname)\r\n",
        "            temp_list.append(filename)\r\n",
        "            # imagePath = os.path.join(dirname, filename)\r\n",
        "            images_to_display.append(temp_list)\r\n",
        "            counter = counter + 1\r\n",
        "\r\n",
        "    #print(images_to_display)\r\n",
        "    return render_template('retreive_images.html',\r\n",
        "                           images_to_display=images_to_display)\r\n",
        "    #return redirect(url_for('train_and_save'))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "classes_data = pd.read_csv(\"E:/IRMA X-ray dataset/ImageCLEFmed2009_test_codes.03.csv\",sep=';') #usecols=['image_id', '05_class'] \r\n",
        "# Preview the first 5 lines of the loaded data \r\n",
        "# print(len(data))\r\n",
        "classes_data = classes_data.set_index(\"image_id\", drop = False)\r\n",
        "# print(classes_data)\r\n",
        "classes_data.head()\r\n",
        "\r\n",
        "# print(classes_data.at[14642,\"05_class\"])\r\n",
        "\r\n",
        "\r\n",
        "# preparing intermediate DataFrame\r\n",
        "datasetPath = Path('E:/IRMA X-ray dataset/ImageCLEFmed2009_test.03/ImageCLEFmed2009_test.03')\r\n",
        "df = pd.DataFrame()\r\n",
        "myimagepath = [] \r\n",
        "classesname = []\r\n",
        "filesname = []\r\n",
        "directoryname = []\r\n",
        "for dirname, _, filenames in os.walk(datasetPath):\r\n",
        "    for filename in filenames:\r\n",
        "        directoryname.append(dirname)\r\n",
        "        imagePath = os.path.join(dirname, filename)\r\n",
        "        filesname.append(filename)\r\n",
        "        myimagepath.append(imagePath)\r\n",
        "        imageID = util.getImageID(filename)\r\n",
        "        #print(imageID, classeName)\r\n",
        "        classesname.append(classes_data.at[int(imageID),\"05_class\"])\r\n",
        "        #print(imagePath, className)        \r\n",
        "df['image'] ,df['classe'], df['filename'],df['directoryname']= [myimagepath,classesname,filesname,directoryname]\r\n",
        "df.head()\r\n",
        "\r\n",
        "#getLabels From Csv\r\n",
        "#Check if there are some settings to change "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               image classe   filename  \\\n",
              "0  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...     15  10358.png   \n",
              "1  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...     31  11198.png   \n",
              "2  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...     56  11416.png   \n",
              "3  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...     \\N  11424.png   \n",
              "4  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...      9  11426.png   \n",
              "\n",
              "                                       directoryname  \n",
              "0  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...  \n",
              "1  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...  \n",
              "2  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...  \n",
              "3  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...  \n",
              "4  E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>classe</th>\n",
              "      <th>filename</th>\n",
              "      <th>directoryname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "      <td>15</td>\n",
              "      <td>10358.png</td>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "      <td>31</td>\n",
              "      <td>11198.png</td>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "      <td>56</td>\n",
              "      <td>11416.png</td>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "      <td>\\N</td>\n",
              "      <td>11424.png</td>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "      <td>9</td>\n",
              "      <td>11426.png</td>\n",
              "      <td>E:\\IRMA X-ray dataset\\ImageCLEFmed2009_test.03...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# preparing intermediate DataFrame\r\n",
        "# Loag data label from folders names\r\n",
        "################################################################Labels From folder name####################################################\r\n",
        "# datasetPath = Path('E:/Medical MNIST/New folder') \r\n",
        "# df = pd.DataFrame()\r\n",
        "# myimagepath = [] \r\n",
        "# classesname = []\r\n",
        "# filesname = []\r\n",
        "# directoryname = []\r\n",
        "# for dirname, _, filenames in os.walk(datasetPath):\r\n",
        "#     for filename in filenames:\r\n",
        "#         directoryname.append(dirname)\r\n",
        "#         imagePath = os.path.join(dirname, filename)\r\n",
        "#         filesname.append(filename)\r\n",
        "#         myimagepath.append(imagePath)\r\n",
        "#         c = util.getImageClass(imagePath)\r\n",
        "#         #print(filename, c, )\r\n",
        "#         classesname.append(c)\r\n",
        "#         # print(filesname)        \r\n",
        "# df['image'] ,df['classe'], df['filename'],df['directoryname']= [myimagepath,classesname,filesname,directoryname]\r\n",
        "# df.head()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        " "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "#summary(ConvAutoencoder_v2().to(device),(3,512,512))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19m7JhxRHDgA",
        "outputId": "f5e96a8c-892a-4516-cd5f-899f6dd052bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model and Save"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "@app.route('/train', methods=['POST'])\r\n",
        "def train_and_save():\r\n",
        "    optimizer = request.form['optimizer']\r\n",
        "    learnin_rate = request.form['lr']\r\n",
        "    epochs = request.form['epochs']\r\n",
        "    batch_size = request.form['batchsize']\r\n",
        "    modelName = request.form['modelName']\r\n",
        "    print(modelName)\r\n",
        "\r\n",
        "    model_name_info_ = modelName +'_'+  optimizer +'_'+ learnin_rate +'_'+ epochs  +'_'+ batch_size\r\n",
        "    \r\n",
        "    \r\n",
        "    # #TODO add function called train with parameters\r\n",
        "    #Check if first if there any information in the session\r\n",
        "    if \"train_set_path\" in session:\r\n",
        "        train_set_path = session['train_set_path']\r\n",
        "        #print('sldflsdjflk')\r\n",
        "    else:\r\n",
        "        #print('aaaaa')\r\n",
        "        render_template('train_model.html')\r\n",
        "\r\n",
        "\r\n",
        "        \r\n",
        "    #TODO add function to preparing trainset intermediate DataFrame\r\n",
        "    # preparing intermediate DataFrame\r\n",
        "    datasetPath = Path(train_set_path)\r\n",
        "    df = pd.DataFrame()\r\n",
        "    myfilename = [] \r\n",
        "    for dirname, _, filenames in os.walk(datasetPath):\r\n",
        "        for filename in filenames:\r\n",
        "            #print(os.path.join(dirname, filename))\r\n",
        "            myfilename.append(os.path.join(dirname, filename))\r\n",
        "    df['image'] = myfilename\r\n",
        "    df.head()\r\n",
        "    #print(df)\r\n",
        "\r\n",
        "    EPOCHS = int(epochs)\r\n",
        "    NUM_BATCHES = int(batch_size)\r\n",
        "    RETRAIN = False\r\n",
        "\r\n",
        "    # EPOCHS,NUM_BATCHES,df, \r\n",
        "    train_set, validate_set = util.prepare_data(DF=df)\r\n",
        "\r\n",
        "    dataloaders = {'train': DataLoader(train_set, batch_size=NUM_BATCHES, shuffle=True, num_workers=1) ,\r\n",
        "                    'val':DataLoader(validate_set, batch_size=NUM_BATCHES, num_workers=1)\r\n",
        "                    }\r\n",
        "\r\n",
        "    #To show images\r\n",
        "    # images = next(iter(DataLoader(train_set, batch_size=NUM_BATCHES, shuffle=True, num_workers=1)))\r\n",
        "    # helper.imshow(images[31], normalize=False)\r\n",
        "\r\n",
        "    dataset_sizes = {'train': len(train_set),'val':len(validate_set)}\r\n",
        "\r\n",
        "    model = ConvAutoencoder_v2().to(device)\r\n",
        "\r\n",
        "    criterion = nn.MSELoss()\r\n",
        "    # Observe that all parameters are being optimized\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=float(learnin_rate)) if (optimizer==\"Adam\") else torch.optim.SGD(model.parameters(), lr=float(learnin_rate)) \r\n",
        "    # Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)#this was commented\r\n",
        "\r\n",
        "    #Training Fucntions\r\n",
        "    model, optimizer, loss = util.train_model(\r\n",
        "                    model=model,\r\n",
        "                    dataloaders = dataloaders,\r\n",
        "                    dataset_sizes = dataset_sizes,\r\n",
        "                    criterion=criterion, \r\n",
        "                    optimizer=optimizer, \r\n",
        "                    scheduler=exp_lr_scheduler,\r\n",
        "                    num_epochs=EPOCHS)\r\n",
        "\r\n",
        "    \r\n",
        "    #Save the trained model \r\n",
        "    torch.save({ 'epoch': EPOCHS, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': loss, }, app.config['UPLOAD_FOLDER']+'/Models/'+model_name_info_+'.pt')\r\n",
        "\r\n",
        "    return redirect(url_for('dashboard_page'))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Trained Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# https://stackoverflow.com/questions/36158058/torch-save-tensor-to-csv-file"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# # #TODO add function to load query image\r\n",
        "# # #Uploading Query Image\r\n",
        "\r\n",
        "#Uploading query image\r\n",
        "# @app.route('/uploadQueryImage', methods=['POST'])\r\n",
        "# def upload_image():\r\n",
        "#     imagefile = request.files['imagefile']\r\n",
        "#     image_path = QUERY_IMAGE_UPLOAD_FOLDER + imagefile.filename\r\n",
        "#     imagefile = Utils.pre_processing(imagefile)\r\n",
        "#     imagefile.save(image_path)\r\n",
        "#     #redirect(url_for(\"extract_query_image_features\", image_path=image_path))\r\n",
        "#     return redirect(url_for('home_page'))\r\n",
        "\r\n",
        "# #Uploading query image\r\n",
        "# @app.route('/uploadQueryImage', methods=['POST'])\r\n",
        "# def upload_image():\r\n",
        "#     imagefile = request.files['file']\r\n",
        "#     number_of_retreived_images = request.form['numberRetreivedImages']\r\n",
        "#     model = request.form['model']\r\n",
        "#     fileName = imagefile.filename\r\n",
        "#     image_path = QUERYIMAGEPATH +  fileName\r\n",
        "#     fileName = imagefile.filename\r\n",
        "#     #img = Image.open(imagefile)\r\n",
        "#     #imagefile = util.pre_processing(img)\r\n",
        "#     imagefile.save(image_path)\r\n",
        "\r\n",
        "#     print(QUERYIMAGEPATH,fileName)\r\n",
        "#     #redirect(url_for(\"extract_query_image_features\", image_path=image_path))\r\n",
        "#     return render_template('retreive_images.html',p=QUERYIMAGEPATH, f= fileName)\r\n",
        "\r\n",
        "def getFileName(query_image_file_name):\r\n",
        "    x = query_image_file_name.split(\".\")\r\n",
        "    query_image_file_name = x[0]\r\n",
        "    return query_image_file_name\r\n",
        "\r\n",
        "def getQueryImageFolderPath(query_image_file_name,test_set_path):\r\n",
        "    query_image_file_name = getFileName(query_image_file_name) \r\n",
        "    for dirname, _, filenames in os.walk(test_set_path):\r\n",
        "        for filename in filenames:\r\n",
        "            filename = getFileName(filename) \r\n",
        "            if query_image_file_name == filename:\r\n",
        "                return str(dirname)\r\n",
        "\r\n",
        "# test = getQueryImageFolderPath('000001.jpeg','E:/Medical MNIST/New folder')\r\n",
        "\r\n",
        "def getQueryImageClassFromFolder(queryImagePath):\r\n",
        "    queryImagePath = queryImagePath.split(\"\\\\\")\r\n",
        "    queryImagePath = queryImagePath[len(queryImagePath)-1]\r\n",
        "    return queryImagePath \r\n",
        "\r\n",
        "# getQueryImageClassFromFolder(test)\r\n",
        "\r\n",
        "\r\n",
        "@app.route('/search', methods=['POST'])\r\n",
        "def search():\r\n",
        "    imagefile = request.files['image']\r\n",
        "    number_of_retreived_images = request.form['imagesCount']\r\n",
        "    fileName = imagefile.filename\r\n",
        "    image_path = QUERYIMAGEPATH +  fileName\r\n",
        "    fileName = imagefile.filename\r\n",
        "    imagefile.save(image_path)\r\n",
        "    #get transformations\r\n",
        "\r\n",
        "    path = session['model_path']\r\n",
        "    loaded_model = util.load_model_from_dir(path)\r\n",
        "    query_image_latent_features = util.get_image_latent_features(image_path, transformations, loaded_model)\r\n",
        "\r\n",
        "\r\n",
        "    index_dict = pickle.loads(open(app.config['UPLOAD_FOLDER'] +'/'+ 'index_dict.pickle', \"rb\").read())\r\n",
        "\r\n",
        "    results = util.perform_search(query_image_latent_features, index_dict, int(number_of_retreived_images))\r\n",
        "    print(results)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    #here\r\n",
        "    query_image_name = getFileName(fileName)\r\n",
        "    query_image_folder = getQueryImageFolderPath(query_image_name,'E:/Medical MNIST/New folder')\r\n",
        "    query_image_class = getQueryImageClassFromFolder(str(query_image_folder))\r\n",
        "\r\n",
        "\r\n",
        "    # print('*********************************** image_path', image_path)\r\n",
        "    # print('*********************************** query_image_class', query_image_class)\r\n",
        "    images_to_display = []\r\n",
        "\r\n",
        "    my_params = pickle.loads(open(app.config['UPLOAD_FOLDER'] +'/'+ 'my_params.pickle', \"rb\").read())\r\n",
        "    # loop over the results\r\n",
        "    for (d, j) in results:\r\n",
        "        temp_list = []\r\n",
        "        temp_list.append(my_params['diractoriesNames'][j])\r\n",
        "        temp_list.append(my_params['filesNames'][j])\r\n",
        "        img_classe = my_params['classes'][j]\r\n",
        "        temp_list.append(img_classe)\r\n",
        "        border_coloer = 'rgb(35, 171, 63)' if (query_image_class==img_classe) else 'rgb(226, 44, 44)'\r\n",
        "        temp_list.append(border_coloer)\r\n",
        "        temp_list.append(d)\r\n",
        "        images_to_display.append(temp_list)\r\n",
        "\r\n",
        "    \r\n",
        "    return jsonify({'data': render_template('list_many_values.html', images_to_display=images_to_display)})\r\n",
        "\r\n",
        "    #return render_template('retreive_images.html',images_to_display=images_to_display,p=QUERYIMAGEPATH, f= fileName)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "app.run()\r\n",
        "# #Running the app\r\n",
        "# if __name__ == \"__main__\":\r\n",
        "#     app.run(debug=True)\r\n",
        "%tb"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__' (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://89c081c0a091.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [09/Jul/2021 12:12:25] \"GET /searchPage HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d:\\Developement\\PFE-CBIR-APP\\uploads\\Models\\conv_autoencoder_v2_Exp21.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [09/Jul/2021 12:12:26] \"GET /static/lib/fontawesome-free/css/all.min.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:26] \"GET /static/lib/ionicons/css/ionicons.min.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:26] \"GET /static/lib/ion-rangeslider/css/ion.rangeSlider.skinFlat.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:26] \"GET /static/lib/amazeui-datetimepicker/css/amazeui.datetimepicker.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:26] \"GET /static/lib/select2/css/select2.min.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:26] \"GET /static/lib/ion-rangeslider/css/ion.rangeSlider.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:26] \"GET /static/lib/typicons.font/typicons.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:26] \"GET /static/lib/spectrum-colorpicker/spectrum.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/jquery-simple-datetimepicker/jquery.simple-dtpicker.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/pickerjs/picker.min.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/css/retreive_images.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/css/azia.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/typicons.font/typicons.woff HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/jquery/jquery.min.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/jquery-ui/ui/widgets/datepicker.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/bootstrap/js/bootstrap.bundle.min.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/ionicons/ionicons.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/jquery.maskedinput/jquery.maskedinput.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/spectrum-colorpicker/spectrum.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/select2/js/select2.min.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/ion-rangeslider/js/ion.rangeSlider.min.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/amazeui-datetimepicker/js/amazeui.datetimepicker.min.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/lib/jquery-simple-datetimepicker/jquery.simple-dtpicker.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:27] \"GET /static/js/jquery.cookie.js HTTP/1.1\" 404 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:28] \"GET /static/lib/pickerjs/picker.min.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:28] \"GET /static/js/azia.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:28] \"GET /static/js/papaparse.min.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:28] \"GET /static/js/retreive_images.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:28] \"GET /static/js/retreive_images_form.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:28] \"GET /static/lib/ionicons/ionicons/ionicons.suuqn5vt.js HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:28] \"GET /static/js/jquery.cookie.js HTTP/1.1\" 404 -\n",
            "127.0.0.1 - - [09/Jul/2021 12:12:28] \"GET /static/lib/bootstrap/js/bootstrap.bundle.min.js.map HTTP/1.1\" 404 -\n"
          ]
        }
      ],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model-Structure-and-Training.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "324e240ea573fd3d8056e12ea70d483238364e9b42112e18bb174b35d8d396b2"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}